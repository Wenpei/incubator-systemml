{"name":"Incubator-systemml","tagline":"Mirror of Apache SystemML (Incubating)","body":"# SystemML\r\n\r\nSystemML is a flexible, scalable machine learning (ML) system.\r\nSystemML's distinguishing characteristics are: (1) algorithm customizability,\r\n(2) multiple execution modes, including Standalone, Hadoop Batch, and Spark Batch,\r\nand (3) automatic optimization.\r\n\r\n[SystemML](http://systemml.apache.org/) is now an Apache Incubator project.\r\nThe latest project documentation can be found at the \r\n[SystemML Documentation](http://apache.github.io/incubator-systemml/) web site on GitHub.\r\n\r\n\r\n### Algorithm Customizability\r\n\r\nML algorithms in SystemML are specified in a high-level, declarative machine learning (DML) language.\r\nAlgorithms can be expressed in either an R-like syntax or a Python-like syntax. DML includes\r\nlinear algebra primitives, statistical functions, and additional constructs.\r\n\r\nThis high-level language significantly increases the productivity of\r\ndata scientists as it provides (1) full flexibility in expressing custom\r\nanalytics and (2) data independence from the underlying input formats and\r\nphysical data representations.\r\n\r\n\r\n### Multiple Execution Modes\r\n\r\nSystemML computations can be executed in a variety of different modes. To begin with, SystemML\r\ncan be operated in Standalone mode on a single machine, allowing data scientists to develop\r\nalgorithms locally without need of a distributed cluster. Algorithms can be distributed across Hadoop or Spark.\r\nThis flexibility allows the utilization of an organization's existing resources and expertise. In addition, SystemML\r\ncan be operated via Java, Scala, and Python. SystemML also features an embedded API for scoring models.\r\n\r\n\r\n### Automatic Optimization\r\n\r\nAlgorithms specified in DML are dynamically compiled and optimized based on data and cluster characteristics\r\nusing rule-based and cost-based optimization techniques. The optimizer automatically generates hybrid runtime\r\nexecution plans ranging from in-memory single-node execution to distributed computations on Spark or Hadoop.\r\nThis ensures both efficiency and scalability. Automatic optimization reduces or eliminates the need to hand-tune\r\ndistributed runtime execution plans and system configurations.\r\n\r\n\r\n* * *\r\n\r\n## Building SystemML\r\n\r\nSystemML is built using [Apache Maven](http://maven.apache.org/).\r\nSystemML will build on Windows, Linux, or MacOS and requires Maven 3 and Java 7 (or higher).\r\nTo build SystemML, run:\r\n\r\n    mvn clean package\r\n\r\n\r\n* * *\r\n\r\n## Testing SystemML\r\n\r\nSystemML features a comprehensive set of integration tests. To perform these tests, run:\r\n\r\n    mvn verify \r\n\r\nNote: these tests require [R](https://www.r-project.org/) to be installed and available as part of the PATH variable on the machine on which you are running these tests. \r\n\r\nIf required, please install the following packages in R:\r\n\r\n    install.packages(c(\"batch\", \"bitops\", \"boot\", \"caTools\", \"data.table\", \"doMC\", \"doSNOW\", \"ggplot2\", \"glmnet\", \"lda\", \"Matrix\", \"matrixStats\", \"moments\", \"plotrix\", \"psych\", \"reshape\", \"topicmodels\", \"wordcloud\"), dependencies=TRUE) \r\n\r\n\r\n* * *\r\n\r\n## Running SystemML in Standalone Mode\r\n\r\nSystemML can run in distributed mode as well as in local standalone mode. We'll operate in standalone mode in this guide. \r\nAfter you built SystemML from source (```mvn clean package```) the standalone mode can be executed either on Mac/Unix using the ```./bin/systemml``` script or on Windows using the ```.\\bin\\systemml.bat``` batch file. \r\n\r\nIf you run from the script from the project root folder ```./``` or from the ```./bin``` folder, then the output files from running SystemML will be created inside the ```./temp``` folder to keep them separate from the SystemML source files managed by Git. The output files for all of the examples in this guide will be created under the ```./temp``` folder.\r\n\r\nThe runtime behavior and logging behavior of SystemML can be customized by editing the files ```./conf/SystemML-config.xml``` and ```./conf/log4j.properties```. Both files will be created from their corresponding ```*.template``` files during the first execution of the SystemML executable script.\r\n\r\nWhen invoking the ```./bin/systemml``` or ```.\\bin\\systemml.bat``` with any of the prepackaged DML scripts you can omit the relative path to the DML script file. The following two commands are equivalent:\r\n\r\n    ./bin/systemml ./scripts/datagen/genLinearRegressionData.dml -nvargs numSamples=1000 numFeatures=50 maxFeatureValue=5 maxWeight=5 addNoise=FALSE b=0 sparsity=0.7 output=linRegData.csv format=csv perc=0.5\r\n\r\n    ./bin/systemml genLinearRegressionData.dml -nvargs numSamples=1000 numFeatures=50 maxFeatureValue=5 maxWeight=5 addNoise=FALSE b=0 sparsity=0.7 output=linRegData.csv format=csv perc=0.5\r\n\r\nIn this guide we invoke the command with the relative folder to make it easier to look up the source of the DML scripts.\r\n\r\n\r\n* * *\r\n\r\n## Algorithms\r\n\r\nSystemML features a suite of algorithms that can be grouped into five broad categories:\r\nDescriptive Statistics, Classification, Clustering, Regression, and Matrix Factorization. Detailed descriptions of\r\nthese algorithms can be found in the Algorithm Reference packaged with SystemML.\r\n\r\n\r\n* * *\r\n\r\n## Linear Regression Example\r\n\r\nAs an example of the capabilities and power of SystemML and DML, let's consider the Linear Regression algorithm.\r\nWe require sets of data to train and test our model. To obtain this data, we can either use real data or\r\ngenerate data for our algorithm. The [UCI Machine Learning Repository Datasets](https://archive.ics.uci.edu/ml/datasets.html)\r\nis one location for real data. Use of real data typically involves some degree of data wrangling. In the following\r\nexample, we will use SystemML to generate random data to train and test our model.\r\n\r\nThis example consists of the following parts:\r\n\r\n  * [Run DML Script to Generate Random Data](#run-dml-script-to-generate-random-data)\r\n  * [Divide Generated Data into Two Sample Groups](#divide-generated-data-into-two-sample-groups)\r\n  * [Split Label Column from First Sample](#split-label-column-from-first-sample)\r\n  * [Split Label Column from Second Sample](#split-label-column-from-second-sample)\r\n  * [Train Model on First Sample](#train-model-on-first-sample)\r\n  * [Test Model on Second Sample](#test-model-on-second-sample)\r\n\r\nSystemML is distributed in several packages, including a standalone package. We'll operate in Standalone mode in this example.\r\n\r\n<a name=\"run-dml-script-to-generate-random-data\" />\r\n\r\n### Run DML Script to Generate Random Data\r\n\r\nWe can execute the `genLinearRegressionData.dml` script in Standalone mode using either the `systemml` or `systemml.bat` file.\r\nIn this example, we'll generate a matrix of 1000 rows of 50 columns of test data, with sparsity 0.7. In addition to this, a 51<sup>st</sup> column consisting of labels will\r\nbe appended to the matrix.\r\n\r\n    ./bin/systemml ./scripts/datagen/genLinearRegressionData.dml -nvargs numSamples=1000 numFeatures=50 maxFeatureValue=5 maxWeight=5 addNoise=FALSE b=0 sparsity=0.7 output=linRegData.csv format=csv perc=0.5\r\n\r\nThis generates the following files inside the ```./temp``` folder:\r\n\r\n    linRegData.csv      # 1000 rows of 51 columns of doubles (50 data columns and 1 label column), csv format\r\n    linRegData.csv.mtd  # metadata file\r\n\r\n\r\n<a name=\"divide-generated-data-into-two-sample-groups\" />\r\n\r\n### Divide Generated Data into Two Sample Groups\r\n\r\nNext, we'll create two subsets of the generated data, each of size ~50%. We can accomplish this using the `sample.dml` script.\r\nThis script will randomly sample rows from the `linRegData.csv` file and place them into 2 files.\r\n\r\nTo do this, we need to create a csv file for the `sv` named argument (see `sample.dml` for more details),\r\nwhich I called `perc.csv`. This file was generated in previous step and looks like:\r\n\r\n    0.5\r\n    0.5\r\n\r\n\r\nThis will create two sample groups of roughly 50 percent each. \r\n\r\nNow, the `sample.dml` script can be run.\r\n\r\n    ./bin/systemml ./scripts/utils/sample.dml -nvargs X=linRegData.csv sv=perc.csv O=linRegDataParts ofmt=csv\r\n\r\n\r\nThis script creates two partitions of the original data and places them in a `linRegDataParts` folder. The files created are\r\nas follows:\r\n\r\n    linRegDataParts/1       # first partition of data, ~50% of rows of linRegData.csv, csv format\r\n    linRegDataParts/1.mtd   # metadata\r\n    linRegDataParts/2       # second partition of data, ~50% of rows of linRegData.csv, csv format\r\n    linRegDataParts/2.mtd   # metadata\r\n\r\n\r\nThe `1` file contains the first partition of data, and the `2` file contains the second partition of data.\r\nAn associated metadata file describes\r\nthe nature of each partition of data. If we open `1` and `2` and look at the number of rows, we can see that typically\r\nthe partitions are not exactly 50% but instead are close to 50%. However, we find that the total number of rows in the\r\noriginal data file equals the sum of the number of rows in `1` and `2`.\r\n\r\n\r\n<a name=\"split-label-column-from-first-sample\" />\r\n\r\n### Split Label Column from First Sample\r\n\r\nThe next task is to split the label column from the first sample. We can do this using the `splitXY.dml` script.\r\n\r\n    ./bin/systemml ./scripts/utils/splitXY.dml -nvargs X=linRegDataParts/1 y=51 OX=linRegData.train.data.csv OY=linRegData.train.labels.csv ofmt=csv\r\n\r\nThis splits column 51, the label column, off from the data. When done, the following files have been created.\r\n\r\n    linRegData.train.data.csv        # training data of 50 columns, csv format\r\n    linRegData.train.data.csv.mtd    # metadata\r\n    linRegData.train.labels.csv      # training labels of 1 column, csv format\r\n    linRegData.train.labels.csv.mtd  # metadata\r\n\r\n\r\n<a name=\"split-label-column-from-second-sample\" />\r\n\r\n### Split Label Column from Second Sample\r\n\r\nWe also need to split the label column from the second sample.\r\n\r\n    ./bin/systemml ./scripts/utils/splitXY.dml -nvargs X=linRegDataParts/2 y=51 OX=linRegData.test.data.csv OY=linRegData.test.labels.csv ofmt=csv\r\n\r\nThis splits column 51 off the data, resulting in the following files:\r\n\r\n    linRegData.test.data.csv        # test data of 50 columns, csv format\r\n    linRegData.test.data.csv.mtd    # metadata\r\n    linRegData.test.labels.csv      # test labels of 1 column, csv format\r\n    linRegData.test.labels.csv.mtd  # metadata\r\n\r\n\r\n<a name=\"train-model-on-first-sample\" />\r\n\r\n### Train Model on First Sample\r\n\r\nNow, we can train our model based on the first sample. To do this, we utilize the `LinearRegDS.dml` (Linear Regression\r\nDirect Solve) script. Note that SystemML also includes a `LinearRegCG.dml` (Linear Regression Conjugate Gradient) algorithm \r\nfor situations where the number of features is large.\r\n\r\n    ./bin/systemml ./scripts/algorithms/LinearRegDS.dml -nvargs X=linRegData.train.data.csv Y=linRegData.train.labels.csv B=betas.csv fmt=csv\r\n\r\nThis will generate the following files:\r\n\r\n    betas.csv      # betas, 50 rows of 1 column, csv format\r\n    betas.csv.mtd  # metadata\r\n\r\nThe LinearRegDS.dml script generates statistics to standard output similar to the following.\r\n\r\n\tBEGIN LINEAR REGRESSION SCRIPT\r\n\tReading X and Y...\r\n\tCalling the Direct Solver...\r\n\tComputing the statistics...\r\n\tAVG_TOT_Y,-2.160284487670675\r\n\tSTDEV_TOT_Y,66.86434576808432\r\n\tAVG_RES_Y,-3.3127468704080085E-10\r\n\tSTDEV_RES_Y,1.7231785003947183E-8\r\n\tDISPERSION,2.963950542926297E-16\r\n\tPLAIN_R2,1.0\r\n\tADJUSTED_R2,1.0\r\n\tPLAIN_R2_NOBIAS,1.0\r\n\tADJUSTED_R2_NOBIAS,1.0\r\n\tPLAIN_R2_VS_0,1.0\r\n\tADJUSTED_R2_VS_0,1.0\r\n\tWriting the output matrix...\r\n\tEND LINEAR REGRESSION SCRIPT\r\n\r\nNow that we have our `betas.csv`, we can test our model with our second set of data.\r\n\r\n\r\n<a name=\"test-model-on-second-sample\" />\r\n\r\n### Test Model on Second Sample\r\n\r\nTo test our model on the second sample, we can use the `GLM-predict.dml` script. This script can be used for both\r\nprediction and scoring. Here, we're using it for scoring since we include the `Y` named argument. Our `betas.csv`\r\nfile is specified as the `B` named argument.  \r\n\r\n    ./bin/systemml ./scripts/algorithms/GLM-predict.dml -nvargs X=linRegData.test.data.csv Y=linRegData.test.labels.csv B=betas.csv fmt=csv\r\n\r\nThis generates the following statistics to standard output.\r\n\r\n\tLOGLHOOD_Z,,FALSE,NaN\r\n\tLOGLHOOD_Z_PVAL,,FALSE,NaN\r\n\tPEARSON_X2,,FALSE,1.895530994504798E-13\r\n\tPEARSON_X2_BY_DF,,FALSE,4.202951207327712E-16\r\n\tPEARSON_X2_PVAL,,FALSE,1.0\r\n\tDEVIANCE_G2,,FALSE,0.0\r\n\tDEVIANCE_G2_BY_DF,,FALSE,0.0\r\n\tDEVIANCE_G2_PVAL,,FALSE,1.0\r\n\tLOGLHOOD_Z,,TRUE,NaN\r\n\tLOGLHOOD_Z_PVAL,,TRUE,NaN\r\n\tPEARSON_X2,,TRUE,1.895530994504798E-13\r\n\tPEARSON_X2_BY_DF,,TRUE,4.202951207327712E-16\r\n\tPEARSON_X2_PVAL,,TRUE,1.0\r\n\tDEVIANCE_G2,,TRUE,0.0\r\n\tDEVIANCE_G2_BY_DF,,TRUE,0.0\r\n\tDEVIANCE_G2_PVAL,,TRUE,1.0\r\n\tAVG_TOT_Y,1,,1.0069397725436522\r\n\tSTDEV_TOT_Y,1,,68.29092137526905\r\n\tAVG_RES_Y,1,,-4.1450397073455047E-10\r\n\tSTDEV_RES_Y,1,,2.0519206226041048E-8\r\n\tPRED_STDEV_RES,1,TRUE,1.0\r\n\tPLAIN_R2,1,,1.0\r\n\tADJUSTED_R2,1,,1.0\r\n\tPLAIN_R2_NOBIAS,1,,1.0\r\n\tADJUSTED_R2_NOBIAS,1,,1.0\r\n\r\n\r\nWe see that the STDEV_RES_Y value of the testing phase is of similar magnitude\r\nto the value obtained from the model training phase.\r\n\r\nFor convenience, we can encapsulate our DML invocations in a single script:\r\n\r\n\t#!/bin/bash\r\n\t\r\n\t./bin/systemml ./scripts/datagen/genLinearRegressionData.dml -nvargs numSamples=1000 numFeatures=50 maxFeatureValue=5 maxWeight=5 addNoise=FALSE b=0 sparsity=0.7 output=linRegData.csv format=csv perc=0.5\r\n\t\r\n\t./bin/systemml ./scripts/utils/sample.dml -nvargs X=linRegData.csv sv=perc.csv O=linRegDataParts ofmt=csv\r\n\t\r\n\t./bin/systemml ./scripts/utils/splitXY.dml -nvargs X=linRegDataParts/1 y=51 OX=linRegData.train.data.csv OY=linRegData.train.labels.csv ofmt=csv\r\n\t\r\n\t./bin/systemml ./scripts/utils/splitXY.dml -nvargs X=linRegDataParts/2 y=51 OX=linRegData.test.data.csv OY=linRegData.test.labels.csv ofmt=csv\r\n\t\r\n\t./bin/systemml ./scripts/algorithms/LinearRegDS.dml -nvargs X=linRegData.train.data.csv Y=linRegData.train.labels.csv B=betas.csv fmt=csv\r\n\t\r\n\t./bin/systemml ./scripts/algorithms/GLM-predict.dml -nvargs X=linRegData.test.data.csv Y=linRegData.test.labels.csv B=betas.csv fmt=csv\r\n\r\n\r\nIn this example, we've seen a small part of the capabilities of SystemML. For more detailed information,\r\nplease consult the SystemML Algorithm Reference and SystemML Language Reference.\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}